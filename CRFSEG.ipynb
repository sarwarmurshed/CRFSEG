{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4b4f2fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import datetime\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import copy,torch,torchvision\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import math\n",
    "from itertools import repeat\n",
    "\n",
    "from fvcore.common.file_io import PathManager\n",
    "from fvcore.common.timer import Timer\n",
    "\n",
    "from detectron2.structures import Boxes, BoxMode, PolygonMasks\n",
    "from detectron2.config import *\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.evaluation import RotatedCOCOEvaluator,DatasetEvaluators, inference_on_dataset, coco_evaluation,DatasetEvaluator\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c75083",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name_list = ['Right_Index', 'Right_Middle', 'Right_Ring', 'Right_Little', 'Left_Index', 'Left_Middle', 'Left_Ring', 'Left_Little', 'Right_Thumb', 'Left_Thumb']\n",
    "MetadataCatalog.get('Test').set(thing_classes=class_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e40280",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "\n",
    "# cfg.OUTPUT_DIR = os.path.join(dataset_path, 'output')\n",
    "cfg.OUTPUT_DIR = os.path.join('trained_model')\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "\n",
    "# #used faster_rcnn_R_50_FPN_3x as backbone arch\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\") # Let training initialize from model zoo\n",
    "\n",
    "# #used faster_rcnn_R_101_FPN_3x as backbone arch\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\") # Let training initialize from model zoo\n",
    "\n",
    "\n",
    "cfg.DATASETS.TRAIN = ([\"Train\"])\n",
    "cfg.DATASETS.TEST = ([\"Val\"])\n",
    "\n",
    "cfg.MODEL.MASK_ON=False\n",
    "cfg.MODEL.PROPOSAL_GENERATOR.NAME = \"RRPN\"\n",
    "cfg.MODEL.RPN.HEAD_NAME = \"StandardRPNHead\"\n",
    "cfg.MODEL.RPN.BBOX_REG_WEIGHTS = (10,10,5,5,1)\n",
    "cfg.MODEL.ANCHOR_GENERATOR.NAME = \"RotatedAnchorGenerator\"\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ANGLES = [[-90,-60,-30,0,30,60,90]]\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8 \n",
    "cfg.MODEL.ROI_HEADS.NAME = \"RROIHeads\"\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   #this is far lower than usual.  \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(class_name_list)\n",
    "cfg.MODEL.ROI_BOX_HEAD.POOLER_TYPE = \"ROIAlignRotated\"\n",
    "cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_WEIGHTS = (10,10,5,5,1)\n",
    "cfg.MODEL.ROI_BOX_HEAD.NUM_CONV=4\n",
    "cfg.MODEL.ROI_MASK_HEAD.NUM_CONV=8\n",
    "#cfg.SOLVER.IMS_PER_BATCH = 6 #can be up to  24 for a p100 (6 default)\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1 #can be up to  24 for a p100 (6 default)\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD=1500\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.GAMMA=0.5\n",
    "cfg.SOLVER.STEPS=[1000,2000,4000, 8000, 12000]\n",
    "cfg.SOLVER.MAX_ITER=14000\n",
    "\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = True \n",
    "cfg.DATALOADER.SAMPLER_TRAIN= \"RepeatFactorTrainingSampler\"\n",
    "cfg.DATALOADER.REPEAT_THRESHOLD=0.01\n",
    "# os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)#lets just check our output dir exists\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9507b720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As of 0.3 the XYWHA_ABS box is not supported in the visualizer, this is fixed in master branch atm (19/11/20)\n",
    "class myVisualizer(Visualizer):\n",
    "  \n",
    "    def draw_dataset_dict(self, dic):\n",
    "        annos = dic.get(\"annotations\", None)\n",
    "        print(\"annos before\", annos)\n",
    "        if annos:\n",
    "            if \"segmentation\" in annos[0]:\n",
    "                masks = [x[\"segmentation\"] for x in annos]\n",
    "            else:\n",
    "                masks = None\n",
    "            if \"keypoints\" in annos[0]:\n",
    "                keypts = [x[\"keypoints\"] for x in annos]\n",
    "                keypts = np.array(keypts).reshape(len(annos), -1, 3)\n",
    "            else:\n",
    "                keypts = None\n",
    "            print(\"annos\", annos)\n",
    "            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYWHA_ABS) for x in annos]\n",
    "            print(\"draw_dataset_dict boxes\\n\", boxes)\n",
    "            labels = [x[\"category_id\"] for x in annos]\n",
    "            print(\"labels\", labels)\n",
    "            names = self.metadata.get(\"thing_classes\", None)\n",
    "            print(\"names\", names)\n",
    "            if names:\n",
    "                labels = [names[i] for i in labels]\n",
    "            labels = [\n",
    "                \"{}\".format(i) + (\"|crowd\" if a.get(\"iscrowd\", 0) else \"\")\n",
    "                for i, a in zip(labels, annos)\n",
    "            ]\n",
    "            self.overlay_instances(labels=labels, boxes=boxes, masks=masks, keypoints=keypts)\n",
    "\n",
    "        sem_seg = dic.get(\"sem_seg\", None)\n",
    "        if sem_seg is None and \"sem_seg_file_name\" in dic:\n",
    "            sem_seg = cv2.imread(dic[\"sem_seg_file_name\"], cv2.IMREAD_GRAYSCALE)\n",
    "        if sem_seg is not None:\n",
    "            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.5)\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c553ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_0013499.pth\")\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 #set threshold value to filter our low scordign bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d6441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imname = 'test_image/Image_00_1_1.bmp'\n",
    "\n",
    "im = cv2.imread(imname)\n",
    "outputs = predictor(im)  \n",
    "# print(outputs)  \n",
    "\n",
    "v = myVisualizer(im[:, :, ::-1],\n",
    "              metadata=MetadataCatalog.get(\"Test\"), \n",
    "              scale=0.2)\n",
    "\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "plt.imshow(out.get_image()[:, :, ::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43843127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
