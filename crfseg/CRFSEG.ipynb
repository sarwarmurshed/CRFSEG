{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import datetime\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import copy,torch,torchvision\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import math\n",
    "from itertools import repeat\n",
    "\n",
    "from fvcore.common.file_io import PathManager\n",
    "from fvcore.common.timer import Timer\n",
    "\n",
    "from detectron2.structures import Boxes, BoxMode, PolygonMasks\n",
    "from detectron2.config import *\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.evaluation import RotatedCOCOEvaluator,DatasetEvaluators, inference_on_dataset, coco_evaluation,DatasetEvaluator\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c75083",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name_list = ['Right_Index', 'Right_Middle', 'Right_Ring', 'Right_Little', 'Left_Index', 'Left_Middle', 'Left_Ring', 'Left_Little', 'Right_Thumb', 'Left_Thumb']\n",
    "MetadataCatalog.get('Test').set(thing_classes=class_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e40280",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "\n",
    "# cfg.OUTPUT_DIR = os.path.join(dataset_path, 'output')\n",
    "cfg.OUTPUT_DIR = os.path.join('trained_model')\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "\n",
    "# #used faster_rcnn_R_50_FPN_3x as backbone arch\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\") # Let training initialize from model zoo\n",
    "\n",
    "# #used faster_rcnn_R_101_FPN_3x as backbone arch\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\") # Let training initialize from model zoo\n",
    "\n",
    "\n",
    "cfg.DATASETS.TRAIN = ([\"Train\"])\n",
    "cfg.DATASETS.TEST = ([\"Val\"])\n",
    "\n",
    "cfg.MODEL.MASK_ON=False\n",
    "cfg.MODEL.PROPOSAL_GENERATOR.NAME = \"RRPN\"\n",
    "cfg.MODEL.RPN.HEAD_NAME = \"StandardRPNHead\"\n",
    "cfg.MODEL.RPN.BBOX_REG_WEIGHTS = (10,10,5,5,1)\n",
    "cfg.MODEL.ANCHOR_GENERATOR.NAME = \"RotatedAnchorGenerator\"\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ANGLES = [[-90,-60,-30,0,30,60,90]]\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8 \n",
    "cfg.MODEL.ROI_HEADS.NAME = \"RROIHeads\"\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   #this is far lower than usual.  \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(class_name_list)\n",
    "cfg.MODEL.ROI_BOX_HEAD.POOLER_TYPE = \"ROIAlignRotated\"\n",
    "cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_WEIGHTS = (10,10,5,5,1)\n",
    "cfg.MODEL.ROI_BOX_HEAD.NUM_CONV=4\n",
    "cfg.MODEL.ROI_MASK_HEAD.NUM_CONV=8\n",
    "#cfg.SOLVER.IMS_PER_BATCH = 6 #can be up to  24 for a p100 (6 default)\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1 #can be up to  24 for a p100 (6 default)\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD=1500\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.GAMMA=0.5\n",
    "cfg.SOLVER.STEPS=[1000,2000,4000, 8000, 12000]\n",
    "cfg.SOLVER.MAX_ITER=14000\n",
    "\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = True \n",
    "cfg.DATALOADER.SAMPLER_TRAIN= \"RepeatFactorTrainingSampler\"\n",
    "cfg.DATALOADER.REPEAT_THRESHOLD=0.01\n",
    "# os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)#lets just check our output dir exists\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9507b720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As of 0.3 the XYWHA_ABS box is not supported in the visualizer, this is fixed in master branch atm (19/11/20)\n",
    "class myVisualizer(Visualizer):\n",
    "  \n",
    "    def draw_dataset_dict(self, dic):\n",
    "        annos = dic.get(\"annotations\", None)\n",
    "        print(\"annos before\", annos)\n",
    "        if annos:\n",
    "            if \"segmentation\" in annos[0]:\n",
    "                masks = [x[\"segmentation\"] for x in annos]\n",
    "            else:\n",
    "                masks = None\n",
    "            if \"keypoints\" in annos[0]:\n",
    "                keypts = [x[\"keypoints\"] for x in annos]\n",
    "                keypts = np.array(keypts).reshape(len(annos), -1, 3)\n",
    "            else:\n",
    "                keypts = None\n",
    "            print(\"annos\", annos)\n",
    "            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYWHA_ABS) for x in annos]\n",
    "            print(\"draw_dataset_dict boxes\\n\", boxes)\n",
    "            labels = [x[\"category_id\"] for x in annos]\n",
    "            print(\"labels\", labels)\n",
    "            names = self.metadata.get(\"thing_classes\", None)\n",
    "            print(\"names\", names)\n",
    "            if names:\n",
    "                labels = [names[i] for i in labels]\n",
    "            labels = [\n",
    "                \"{}\".format(i) + (\"|crowd\" if a.get(\"iscrowd\", 0) else \"\")\n",
    "                for i, a in zip(labels, annos)\n",
    "            ]\n",
    "            self.overlay_instances(labels=labels, boxes=boxes, masks=masks, keypoints=keypts)\n",
    "\n",
    "        sem_seg = dic.get(\"sem_seg\", None)\n",
    "        if sem_seg is None and \"sem_seg_file_name\" in dic:\n",
    "            sem_seg = cv2.imread(dic[\"sem_seg_file_name\"], cv2.IMREAD_GRAYSCALE)\n",
    "        if sem_seg is not None:\n",
    "            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.5)\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c553ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 #set threshold value to filter our low scordign bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8e4bf7-506f-4244-86f5-219a6aba9aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39968d6e-1fc6-4b38-82e7-034f98f2ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(origin, point, angle):\n",
    "    \"\"\"\n",
    "    Rotate a point counterclockwise by a given angle around a given origin.\n",
    "\n",
    "    The angle should be given in radians.\n",
    "    \"\"\"\n",
    "    ox, oy = origin\n",
    "    px, py = point\n",
    "\n",
    "    qx = ox + math.cos(angle) * (px - ox) - math.sin(angle) * (py - oy)\n",
    "    qy = oy + math.sin(angle) * (px - ox) + math.cos(angle) * (py - oy)\n",
    "    return int(qx), int(qy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c43c27e-46f7-437f-9891-38de553e0a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    tag_arr = np.zeros(len(boxes)) # help to find non overlap array\n",
    "    \n",
    "    for b_index, box in enumerate(boxes):\n",
    "        if tag_arr[b_index] == 0:\n",
    "                for b2_index in range(b_index+1, len(boxes)):\n",
    "                    if tag_arr[b2_index] == 0:\n",
    "                        box_overlapped, _ = calculated_iou(boxes[b_index], boxes[b2_index], overlapThresh)\n",
    "    #                     print(box_overlapped)\n",
    "                        if box_overlapped> 0:\n",
    "                             tag_arr[b2_index] = 1\n",
    "                #print(\"tag_arr: \", tag_arr)\n",
    "    \n",
    "    final_box = []\n",
    "    #print(\"tag_arr: \", tag_arr)\n",
    "    for tag_index, tag_value in enumerate(tag_arr):\n",
    "        if tag_arr[tag_index] ==0:\n",
    "            list_box = boxes[tag_index].tolist()\n",
    "            final_box.append(list_box)\n",
    "            \n",
    "            \n",
    "    return final_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb8cf79-e9f3-40df-861f-85a8bf47c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code use modified non-maximum suppression approache to remove overlapped bboxes\n",
    "#this code implement majority voteing or most confident label to remove wrong fingerprint labeling\n",
    "#this code is written for appeding model output results to dataframe\n",
    "#4 co-ordinate of a bounding box are stored\n",
    "\n",
    "#cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "\n",
    "min_iou = 0\n",
    "not_found_image_label = 555.0\n",
    "not_found_bbox_angle = 333.0\n",
    "ZERO = 0\n",
    "number_of_bboxes_in_dataset = 0\n",
    "number_of_bboxes_in_result = 0\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6#set threshold value to filter our low scordign bboxes\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "#insert bb and label to dataframe\n",
    "# for d in random.sample(test_dict, 1):    \n",
    "for d in test_dict:\n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    im_height, im_width, _ = im.shape\n",
    "    #print(im_width, im_height)\n",
    "    origin = im_width/2, im_height/2\n",
    "    outputs = predictor(im)  \n",
    "    predictions= outputs[\"instances\"].to(\"cpu\")\n",
    "    \n",
    "    #############################################################################################\n",
    "    rlt_bbs = predictions.pred_boxes.tensor.numpy() if predictions.has(\"pred_boxes\") else None\n",
    "    #print(len(rlt_bbs))\n",
    "\n",
    "    current_bbs_list = np.zeros((len(rlt_bbs), 5))\n",
    "\n",
    "    num_of_fingers = 0\n",
    "    angle_of_detected_fingers = 0\n",
    "\n",
    "\n",
    "\n",
    "    if len(rlt_bbs) <= 2:\n",
    "        for box in rlt_bbs:\n",
    "                num_of_fingers += 1\n",
    "                #print(box)\n",
    "                angle_of_detected_fingers += box[4]\n",
    "        bbox_angle = angle_of_detected_fingers/num_of_fingers\n",
    "    else:\n",
    "        for box in rlt_bbs[:2]:\n",
    "                num_of_fingers += 1\n",
    "                #print(box)\n",
    "                angle_of_detected_fingers += box[4]\n",
    "        bbox_angle = angle_of_detected_fingers/num_of_fingers\n",
    "\n",
    "\n",
    "    for index, rlt_bb in enumerate(rlt_bbs):\n",
    "        raw_cx = rlt_bb[0]\n",
    "        raw_cy = rlt_bb[1]\n",
    "        raw_w = rlt_bb[2]\n",
    "        raw_h = rlt_bb[3]\n",
    "        #bbox_angle = rlt_bb[4]\n",
    "        #print(raw_cx, raw_cy, w, h, bbox_angle)\n",
    "        #print('origin', origin)\n",
    "        rot_cx, rot_cy = rotate(origin, [raw_cx, raw_cy], math.radians(bbox_angle))\n",
    "    #     print('cx, cy', cx, cy)\n",
    "        x1 = rot_cx-raw_w/2\n",
    "        y1 = rot_cy-raw_h/2\n",
    "        x2 = rot_cx+raw_w/2\n",
    "        y2 = rot_cy+raw_h/2\n",
    "        current_bbs_list[index, 0] = x1\n",
    "        current_bbs_list[index, 1] = y1\n",
    "        current_bbs_list[index, 2] = x2\n",
    "        current_bbs_list[index, 3] = y2\n",
    "        current_bbs_list[index, 4] = index\n",
    "\n",
    "    #print(\"current_bbs_list: \",current_bbs_list)\n",
    "    nms_bbs = non_max_suppression_fast(current_bbs_list, 0.1)\n",
    "  \n",
    "    \n",
    "    \n",
    "    #############################################################################################\n",
    "        \n",
    "    nms_bbs = sorted(nms_bbs)\n",
    "    #print(\"nms_bbs\", nms_bbs)\n",
    "    #print(\"draw_dataset_dict boxes  \\n\", rlt_bbs)\n",
    "    \n",
    "    rlt_cls = predictions.pred_classes.numpy() if predictions.has(\"pred_classes\") else None\n",
    "#     print(\"Predicted levels are: \", (rlt_cls))\n",
    "    \n",
    "    hand_info = rlt_cls[0] #the hand info of most confident fingerprint is cosidered as slap info. \n",
    "                           #If this method not work well, we should consider majority vote method  \n",
    "    \n",
    "    if hand_info <=3:\n",
    "        calculated_labels = [2.0, 3.0, 4.0, 5.0]\n",
    "    elif (hand_info >3) and (hand_info <=7):\n",
    "        calculated_labels = [10.0, 9.0, 8.0, 7.0]\n",
    "    elif (hand_info == 8) or (hand_info == 9):\n",
    "        calculated_labels = [12.0, 11.0]\n",
    "    else:\n",
    "        calculated_labels = not_found_image_label\n",
    "    \n",
    "\n",
    "    found_finger_length = min(len(nms_bbs), len(calculated_labels))\n",
    "    #print(\"rlt_bbs: \",rlt_bbs)\n",
    "    for label_index in range(found_finger_length):\n",
    "        detected_cx = rlt_bbs[int(nms_bbs[label_index][4])][0] #nms_bbs[label_index][0]\n",
    "        detected_cy = rlt_bbs[int(nms_bbs[label_index][4])][1]\n",
    "        detected_w = rlt_bbs[int(nms_bbs[label_index][4])][2]\n",
    "        detected_h = rlt_bbs[int(nms_bbs[label_index][4])][3]\n",
    "        detected_finger_angle = rlt_bbs[int(nms_bbs[label_index][4])][4]\n",
    "        detected_class = calculated_labels[label_index]\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d6441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imname = 'test_image/Image_00_1_1.bmp'\n",
    "\n",
    "im = cv2.imread(imname)\n",
    "outputs = predictor(im)  \n",
    "# print(outputs)  \n",
    "\n",
    "v = myVisualizer(im[:, :, ::-1],\n",
    "              metadata=MetadataCatalog.get(\"Test\"), \n",
    "              scale=0.2)\n",
    "\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "plt.imshow(out.get_image()[:, :, ::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43843127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
