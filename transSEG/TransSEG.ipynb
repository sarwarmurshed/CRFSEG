{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6312c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import xml.etree.ElementTree as X\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4536da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if any import error. Run previous cell and then restart the notebook kernel\n",
    "from mmcv import collect_env\n",
    "collect_env()\n",
    "\n",
    "# Check MMRotate installation\n",
    "import mmrotate\n",
    "print(mmrotate.__version__)\n",
    "\n",
    "# Check MMDetection installation\n",
    "import mmdet\n",
    "print(mmdet.__version__)\n",
    "\n",
    "# Check mmcv installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5640e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmrotate.datasets.builder import ROTATED_DATASETS\n",
    "from mmrotate.datasets.dota import DOTADataset\n",
    "\n",
    "@ROTATED_DATASETS.register_module()\n",
    "class TinyDataset(DOTADataset):\n",
    "    \"\"\"SAR ship dataset for detection.\"\"\"\n",
    "    CLASSES = ('RI', 'RM', 'RR', 'RL', 'LI', 'LM', 'LR', 'LL', 'RT', 'LT',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c36d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MMRotate from the source.\n",
    "!git clone https://github.com/open-mmlab/mmrotate.git\n",
    "%cd mmrotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82933db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use mim to download the pre-trained checkpoints for inference and finetuning.\n",
    "!mim download mmrotate --config roi_trans_swin_tiny_fpn_1x_dota_le90 --dest ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fe4326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmcv.runner import load_checkpoint\n",
    "\n",
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "from mmrotate.models import build_detector\n",
    "\n",
    "# Choose to use a config and initialize the detector\n",
    "config = 'roi_trans_swin_tiny_fpn_1x_dota_le90.py'\n",
    "# Setup a checkpoint file to load\n",
    "checkpoint = 'roi_trans_swin_tiny_fpn_1x_dota_le90-ddeee9ae.pth'\n",
    "\n",
    "# Set the device to be used for evaluation\n",
    "device='cuda:0'\n",
    "\n",
    "# Load the config\n",
    "config = mmcv.Config.fromfile(config)\n",
    "# Set pretrained to be None since we do not need pretrained model here\n",
    "config.model.pretrained = None\n",
    "\n",
    "# Initialize the detector\n",
    "model = build_detector(config.model)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = load_checkpoint(model, checkpoint, map_location=device)\n",
    "\n",
    "# Set the classes of models for inference\n",
    "model.CLASSES = checkpoint['meta']['CLASSES']\n",
    "\n",
    "# We need to set the model's cfg for inference\n",
    "model.cfg = config\n",
    "\n",
    "# Convert the model to GPU\n",
    "model.to(device)\n",
    "# Convert the model into evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c0a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/roi_trans/roi_trans_swin_tiny_fpn_1x_dota_le90.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bca40f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmcv.runner import load_checkpoint\n",
    "\n",
    "from mmdet.apis import inference_detector, show_result_pyplot\n",
    "from mmrotate.models import build_detector\n",
    "from mmdet.apis import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'TinyDataset'\n",
    "cfg.data_root = 'ssdd_tiny/'\n",
    "\n",
    "cfg.data.test.type = 'TinyDataset'\n",
    "cfg.data.test.data_root = 'ssdd_tiny/'\n",
    "cfg.data.test.ann_file = 'val'\n",
    "cfg.data.test.img_prefix = 'images'\n",
    "\n",
    "cfg.data.train.type = 'TinyDataset'\n",
    "cfg.data.train.data_root = 'ssdd_tiny/'\n",
    "cfg.data.train.ann_file = 'train'\n",
    "cfg.data.train.img_prefix = 'images'\n",
    "\n",
    "cfg.data.val.type = 'TinyDataset'\n",
    "cfg.data.val.data_root = 'ssdd_tiny/'\n",
    "cfg.data.val.ann_file = 'val'\n",
    "cfg.data.val.img_prefix = 'images'\n",
    "\n",
    "#print(f'Config:\\n{cfg.pretty_text}')\n",
    "print(cfg.model.roi_head.bbox_head[1])\n",
    "# modify num classes of the model in box head\n",
    "cfg.model.roi_head.bbox_head[0].num_classes = 10\n",
    "cfg.model.roi_head.bbox_head[1].num_classes = 10\n",
    "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
    "\n",
    "# use the mask branch\n",
    "#cfg.load_from = 'roi_trans_swin_tiny_fpn_1x_dota_le90-ddeee9ae.pth'\n",
    "cfg.load_from = '/home/murshed/phd/git_research/ftsegment/rotated_object/transformer/mmrotate-main/demo/mmrotate/tutorial_exps/epoch_6.pth'\n",
    "\n",
    "\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "\n",
    "cfg.optimizer.lr = 0.0001\n",
    "cfg.lr_config.warmup = None\n",
    "cfg.runner.max_epochs = 3\n",
    "cfg.log_config.interval = 10\n",
    "\n",
    "# Change the evaluation metric since we use customized dataset.\n",
    "cfg.evaluation.metric = 'mAP'\n",
    "# We can set the evaluation interval to reduce the evaluation times\n",
    "cfg.evaluation.interval = 3\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 3\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.device='cuda'\n",
    "\n",
    "# We can also use tensorboard to log the training process\n",
    "cfg.log_config.hooks = [\n",
    "    dict(type='TextLoggerHook'),\n",
    "    dict(type='TensorboardLoggerHook')]\n",
    "\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b6fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "\n",
    "\n",
    "# Build dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "#print(cfg.data.train)\n",
    "\n",
    "# Build the detector\n",
    "model = build_detector(\n",
    "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026c8d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '../roi_trans_swin_tiny_fpn_1x_dota_le90_trained.py'\n",
    "checkpoint_file = '../trained_model/transSEG.pth'\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bfd2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mmcv.imread('../../crfseg/test_image/Image_00_1_1.bmp')\n",
    "#img = mmcv.imread('/home/murshed/phd/git_research/ftsegment/datasets/fingerprint/raw_and_rotated_images/9_WT_150127-093901_15.jpeg')\n",
    "model.cfg = cfg\n",
    "result = inference_detector(model, img)\n",
    "show_result_pyplot(model, img, result, score_thr=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df771e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
